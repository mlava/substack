"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const tslib_1 = require("tslib");
const fs_1 = tslib_1.__importDefault(require("fs"));
const compile_1 = tslib_1.__importDefault(require("./internal/compile"));
const toVersion_1 = tslib_1.__importDefault(require("./internal/toVersion"));
const child_process_1 = require("child_process");
const getPackageName_1 = tslib_1.__importDefault(require("./internal/getPackageName"));
const axios_1 = tslib_1.__importDefault(require("axios"));
const mime_types_1 = tslib_1.__importDefault(require("mime-types"));
const path_1 = tslib_1.__importDefault(require("path"));
const esbuild_1 = tslib_1.__importDefault(require("esbuild"));
const appPath_1 = tslib_1.__importDefault(require("./internal/appPath"));
const updateLambdaFunctions_1 = tslib_1.__importDefault(require("./internal/updateLambdaFunctions"));
const zod_1 = require("zod");
const client_s3_1 = require("@aws-sdk/client-s3");
const publish = async ({ api, root = ".", review, version, host = "samepage.network", } = {}) => {
    var _a;
    const token = process.env.GITHUB_TOKEN;
    const destPath = (0, getPackageName_1.default)();
    const assetsDir = path_1.default.join(root, "assets");
    const distDir = path_1.default.join(root, "dist");
    const branch = process.env.GITHUB_HEAD_REF || process.env.GITHUB_REF_NAME || "main";
    if (branch === "main") {
        if (token) {
            console.log(`Preparing to publish zip to destination ${destPath} as version ${version}`);
            const cwd = process.cwd();
            process.chdir(distDir);
            (0, child_process_1.execSync)(`zip -qr ${destPath}.zip .`);
            const opts = {
                headers: {
                    Authorization: `token ${token}`,
                    Accept: "application/vnd.github+json",
                },
            };
            const message = await axios_1.default
                .get(`https://api.github.com/repos/${process.env.GITHUB_REPOSITORY}/commits/${process.env.GITHUB_SHA}`, opts)
                .then((r) => r.data.commit.message)
                .catch((r) => Promise.reject(new Error(`Failed to read commit message for ${process.env.GITHUB_SHA} in ${process.env.GITHUB_REPOSITORY}:\n${JSON.stringify(r.response.data || "No response data found")}`)));
            const release = await axios_1.default
                .post(`https://api.github.com/repos/${process.env.GITHUB_REPOSITORY}/releases`, {
                tag_name: version,
                name: message.length > 50 ? `${message.substring(0, 47)}...` : message,
                body: message.length > 50 ? `...${message.substring(47)}` : "",
            }, opts)
                .catch((r) => {
                const { data } = r.response;
                if (data && data.errors && data.errors[0].code === "already_exists") {
                    return axios_1.default.get(`https://api.github.com/repos/${process.env.GITHUB_REPOSITORY}/releases/tags/${version}`, opts);
                }
                return Promise.reject(new Error(`Failed to read post release ${version} for repo ${process.env.GITHUB_REPOSITORY}:\n${JSON.stringify(data || "No response data found")}`));
            });
            const { tag_name, id } = release.data;
            const assets = fs_1.default.readdirSync(".");
            await Promise.all(assets
                .filter((f) => f !== "package.json")
                .map((asset) => {
                const content = fs_1.default.readFileSync(asset);
                const contentType = mime_types_1.default.lookup(asset);
                return axios_1.default
                    .post(`https://uploads.github.com/repos/${process.env.GITHUB_REPOSITORY}/releases/${id}/assets?name=${asset}`, content, contentType
                    ? {
                        ...opts,
                        headers: {
                            ...opts.headers,
                            "Content-Type": contentType,
                        },
                    }
                    : opts)
                    .catch((e) => {
                    var _a, _b, _c, _d, _e, _f;
                    if (e.response &&
                        Array.isArray((_a = e.response.data) === null || _a === void 0 ? void 0 : _a.errors) &&
                        ((_c = (_b = e.response.data) === null || _b === void 0 ? void 0 : _b.errors[0]) === null || _c === void 0 ? void 0 : _c.code) === "already_exists") {
                        console.error(`Release asset ${asset} already exists`);
                    }
                    else {
                        console.error(`Failed to upload ${asset}:\n${JSON.stringify(((_e = (_d = e.response) === null || _d === void 0 ? void 0 : _d.data) === null || _e === void 0 ? void 0 : _e.errors) ||
                            ((_f = e.response) === null || _f === void 0 ? void 0 : _f.data) ||
                            e.message ||
                            "{}", null, 4)}`);
                    }
                });
            }));
            console.log(`Successfully created github release for version ${tag_name}`);
            process.chdir(cwd);
        }
        else {
            console.warn("Github Release are only created when the GITHUB_TOKEN is set");
        }
        await (0, updateLambdaFunctions_1.default)({
            api,
            out: "out",
            root,
            prefix: `extensions-${destPath.replace(/-samepage$/, "")}-`,
        });
        if (review && fs_1.default.existsSync(path_1.default.join(root, review)) && branch === "main") {
            await (_a = (0, appPath_1.default)(`${root}/${review.replace(/\.[jt]s$/, "")}`), Promise.resolve().then(() => tslib_1.__importStar(require(_a)))).then(
            //@ts-ignore
            (mod) => typeof mod.default === "function" && mod.default());
        }
    }
    else {
        console.warn("Not on main branch, skipping production releases");
    }
    const awsToken = process.env.AWS_ACCESS_KEY_ID;
    if (!!awsToken && host !== "none") {
        const s3 = new client_s3_1.S3({});
        const Bucket = host;
        const artifacts = fs_1.default.existsSync(distDir) ? fs_1.default.readdirSync(distDir) : [];
        const assets = fs_1.default.existsSync(assetsDir) ? fs_1.default.readdirSync(assetsDir) : [];
        const repo = process.env.GITHUB_REPOSITORY || "samepage.network";
        await Promise.all(artifacts
            .flatMap((a) => {
            const Key = `releases/${repo}/${branch === "main" ? "" : `${branch}/`}${a}`;
            const Path = path_1.default.join(distDir, a);
            const KeyLower = Key.toLowerCase();
            // S3 object keys are case insensitive :shakes-fist:
            return Key === KeyLower
                ? [
                    {
                        Key,
                        Path,
                    },
                ]
                : [
                    {
                        Key,
                        Path,
                    },
                    {
                        Key: KeyLower,
                        Path,
                    },
                ];
        })
            .concat(branch === "main"
            ? assets.map((a) => ({
                Key: `assets/${repo
                    .split("/")
                    .slice(-1)[0]
                    .replace(/-samepage$/, "")}/${a}`,
                Path: path_1.default.join(assetsDir, a),
            }))
            : [])
            .map(({ Key, Path }) => s3
            .putObject({
            Bucket,
            Key,
            Body: fs_1.default.createReadStream(Path),
            ContentType: mime_types_1.default.lookup(Path) || "application/octet-stream",
        })
            .then(() => console.log("Uploaded", Path, "to", Key))));
    }
    else {
        console.warn("No access to AWS, skipping S3 uploads");
    }
};
const analyzeMetafile = async (metafile, root = ".") => {
    const text = await esbuild_1.default.analyzeMetafile(metafile);
    const files = text
        .trim()
        .split(/\n/)
        .filter((s) => !!s.trim())
        .map((s) => {
        const file = s.trim();
        const args = /([├└])?\s*([^\s]+)\s*(\d+(?:\.\d)?[kmg]?b)\s*/.exec(file);
        if (!args)
            throw new Error(`Failed to parse ${file} from metadata`);
        const [_, isFile, fileName, size] = args;
        if (!fileName)
            throw new Error(`Failed to parse filename from ${file} in metadata`);
        return { isFile, fileName, size };
    });
    const parseSize = (s) => {
        const [_, value, unit] = /(\d+(?:\.\d)?)([kmg]?b)/.exec(s) || ["0", "b"];
        const mult = unit === "gb"
            ? 1000000000
            : unit === "mb"
                ? 1000000
                : unit === "kb"
                    ? 1000
                    : 1;
        return mult * Number(value);
    };
    const tree = [];
    let maxLength = 0;
    files.forEach((file) => {
        maxLength = Math.max(maxLength, file.fileName.length);
        if (file.isFile) {
            let root = tree.slice(-1)[0];
            const parts = file.fileName.split("/");
            parts.forEach((_, index, all) => {
                const fileName = all.slice(0, index + 1).join("/");
                const size = parseSize(file.size);
                const treeNode = root.children.find((c) => c.fileName === fileName);
                if (treeNode) {
                    treeNode.size += size;
                    root = treeNode;
                }
                else {
                    const newRoot = { children: [], fileName, size };
                    root.children.push(newRoot);
                    root = newRoot;
                }
            });
        }
        else {
            tree.push({
                children: [],
                fileName: file.fileName,
                size: parseSize(file.size),
            });
        }
    });
    const calcSize = (t) => {
        if (t.children.length) {
            t.size = t.children.reduce((p, c) => p + calcSize(c), 0);
        }
        return t.size;
    };
    tree.forEach(calcSize);
    const printTree = (t, level = 0) => t
        .sort((a, b) => b.size - a.size)
        .flatMap((tn) => {
        const indent = "".padStart(level * 2, " ");
        return [
            `${indent}${level ? "├ " : ""}${tn.fileName.padEnd(maxLength + (level ? 6 : 8) - indent.length)}${(tn.size >= 1000000000
                ? `${(tn.size / 1000000000).toFixed(1)}gb`
                : tn.size >= 1000000
                    ? `${(tn.size / 1000000).toFixed(1)}mb`
                    : tn.size >= 1000
                        ? `${(tn.size / 1000).toFixed(1)}kb`
                        : `${tn.size}b `).padStart(7, " ")}`,
            ...printTree(tn.children, level + 1),
        ];
    });
    fs_1.default.writeFileSync(path_1.default.join(root, "analyze.txt"), printTree(tree).join("\n"));
};
const zBuildArgs = zod_1.z.object({
    root: zod_1.z.string().optional(),
    dry: zod_1.z.boolean().optional(),
    review: zod_1.z.string().optional(),
    domain: zod_1.z.string().optional(),
    api: zod_1.z.string().optional(),
    verbose: zod_1.z.boolean().optional(),
    host: zod_1.z.string().optional(),
});
const build = (args = {}) => {
    const { root, review, api, verbose, host } = zBuildArgs.parse(args);
    process.env.NODE_ENV = process.env.NODE_ENV || "production";
    process.env.ORIGIN = process.env.ORIGIN || "https://samepage.network";
    const version = (0, toVersion_1.default)();
    const envExisting = fs_1.default.existsSync(".env")
        ? fs_1.default.readFileSync(".env").toString()
        : "";
    fs_1.default.writeFileSync(".env", `${envExisting.replace(/VERSION=[\d.-]+\n/gs, "")}VERSION=${version}\n`);
    return (0, compile_1.default)({
        opts: args,
        builder: (opts) => esbuild_1.default
            .build({
            ...opts,
            minify: !verbose,
        })
            .then(async (r) => {
            if (!r.metafile)
                return;
            return analyzeMetafile(r.metafile, root);
        }),
    })
        .then(() => args.dry
        ? Promise.resolve()
        : publish({
            review,
            version,
            root,
            api,
            host,
        }))
        .then(() => {
        console.log("done");
        return 0;
    });
};
exports.default = build;
//# sourceMappingURL=build.js.map